{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5418f1ec",
   "metadata": {},
   "source": [
    "\n",
    "## SecureFinAI Contest 2025 Task 3: **FinGPT-Powered Agents for MultiModal Financial Data** \n",
    "\n",
    "### Objective\n",
    "Participants will develop **FinGPT agents** capable of:\n",
    "- Processing **financial document images** (in base64-encoded PNG format).  \n",
    "- Converting images to **structured HTML** format (OCR + HTML generation task).  \n",
    "- Note: This is an image-to-HTML conversion task, not a QA or reasoning task.  \n",
    "\n",
    "### Ground Truth\n",
    "The dataset `TheFinAI/SecureFinAI_Contest_2025-Task_3_EnglishOCR` and `TheFinAI/SecureFinAI_Contest_2025-Task_3_SpanishOCR` provides two key columns:\n",
    "- `image` → base64-encoded PNG image (input).  \n",
    "- `matched_html` → structured HTML generated from OCR + postprocessing (ground truth).  \n",
    "\n",
    "### Evaluation\n",
    "Your model’s predicted HTML is evaluated against `matched_html` using **ROUGE-1**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53d0bc",
   "metadata": {},
   "source": [
    "## 0. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5fd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_repo = \"TheFinAI/SecureFinAI_Contest_2025-Task_3_EnglishOCR\" # hf repo of OCR dataset\n",
    "pred_dir = \"./preds_baseline\"                 # Output directory for predictions\n",
    "model_name = \"baseline\"                        # Used in prediction filenames\n",
    "lang = \"en\"\n",
    "eval_output = \"./eval_rouge_baseline.csv\"\n",
    "max_samples = 5  # Set None for all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f67382",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad80d29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374d7fe8a2074485b0942273972de422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 22:25:04.728372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-01 22:25:04.728964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-01 22:25:04.806620: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-01 22:25:04.967563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-01 22:25:06.670700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.4.2\n",
      "Pytesseract: 4.1.1\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os, base64, io, re, math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# OCR engine\n",
    "try:\n",
    "    import pytesseract\n",
    "except ImportError:\n",
    "    !pip -q install pytesseract pillow\n",
    "    import pytesseract\n",
    "\n",
    "# Rouge evaluation requires 'evaluate'\n",
    "try:\n",
    "    import evaluate\n",
    "except ImportError:\n",
    "    !pip -q install evaluate\n",
    "    import evaluate\n",
    "\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"Pytesseract:\", pytesseract.get_tesseract_version())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97cb61",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d14685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f3cc9d9cb14e03a1c675d164092c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/475 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c70bd0b23e42eb81aee555956e3923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00004.parquet:   0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4325a6d763eb478bae8f8b1bd570356d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00004.parquet:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac716c22ee74e769cf78dbcda8a6ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00004.parquet:   0%|          | 0.00/323M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0d7514ee4a463d85029d13edd3aeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00004.parquet:   0%|          | 0.00/333M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e69fe5d2db4680a2d78c532a99ceb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00002.parquet:   0%|          | 0.00/289M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f719b97930374796bdadd4f90ee6614d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00001-of-00002.parquet:   0%|          | 0.00/282M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63285bd67964a98a936331ab8085a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957c61f4809248de9c54a05e128e63a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>matched_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABnUAAAkjCAIAAABYnF2RAA...</td>\n",
       "      <td>Last Name\\nFirst Name\\nMiddle Name\\nFaltysova\\...</td>\n",
       "      <td>&lt;p class=\"SectionTitle\"&gt;9. Type(s) of Securiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAABnUAAAkjCAIAAABYnF2RAA...</td>\n",
       "      <td>SECURITIES AND EXCHANGE COMMISSION \\nWashingto...</td>\n",
       "      <td>&lt;div class=\"contentwrapper\"&gt;&lt;table id=\"scheade...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  iVBORw0KGgoAAAANSUhEUgAABnUAAAkjCAIAAABYnF2RAA...   \n",
       "1  iVBORw0KGgoAAAANSUhEUgAABnUAAAkjCAIAAABYnF2RAA...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Last Name\\nFirst Name\\nMiddle Name\\nFaltysova\\...   \n",
       "1  SECURITIES AND EXCHANGE COMMISSION \\nWashingto...   \n",
       "\n",
       "                                        matched_html  \n",
       "0  <p class=\"SectionTitle\">9. Type(s) of Securiti...  \n",
       "1  <div class=\"contentwrapper\"><table id=\"scheade...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    dataset = load_dataset(hf_repo, split=\"test\")\n",
    "    # Convert to pandas DataFrame for convenience\n",
    "    data = dataset.to_pandas()\n",
    "except:\n",
    "    # Create a toy dataset if not provided\n",
    "    data = pd.DataFrame({\n",
    "        \"image\": [],\n",
    "        \"matched_html\": [\n",
    "            \"<html><body><p>Total revenue for Q1 was $1.2B.</p></body></html>\",\n",
    "            \"<html><body><p>Operating income increased by 12% year-over-year.</p></body></html>\"\n",
    "        ]\n",
    "    })\n",
    "    print(f\"'{hf_repo}'could not be found, Created toy data\")\n",
    "\n",
    "\n",
    "if max_samples is not None and len(data) > max_samples:\n",
    "    data = data.head(max_samples)\n",
    "\n",
    "print(\"Rows:\", len(data))\n",
    "data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d837bf",
   "metadata": {},
   "source": [
    "## 3. Baseline Agent (OCR → HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3aa4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_agent_from_image(b64_img: str) -> str:\n",
    "    \"\"\"Decode base64 image → OCR → wrap into structured HTML.\"\"\"\n",
    "    if not isinstance(b64_img, str) or not b64_img.strip():\n",
    "        return \"<html><body><p></p></body></html>\"\n",
    "    try:\n",
    "        img_data = base64.b64decode(b64_img)\n",
    "        img = Image.open(io.BytesIO(img_data)).convert(\"RGB\")\n",
    "        text = pytesseract.image_to_string(img, lang=\"eng\")\n",
    "    except Exception as e:\n",
    "        text = \"\"\n",
    "    return f\"<html><body><p>{text.strip()}</p></body></html>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe9359",
   "metadata": {},
   "source": [
    "## 4. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f12ca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 5 predictions to ./preds_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "written = 0\n",
    "for i in tqdm(data.index, desc=\"Predicting\"):\n",
    "    b64_img = data.loc[i, \"image\"] if \"image\" in data.columns else \"\"\n",
    "    pred_html = baseline_agent_from_image(b64_img)\n",
    "    out_path = os.path.join(pred_dir, f\"{model_name}_pred_{i}.html\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(pred_html)\n",
    "    written += 1\n",
    "\n",
    "print(f\"Wrote {written} predictions to {pred_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b08754",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea364ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_html_eval(df, pred_dir, model_name, lang, output_csv):\n",
    "    \"\"\"\n",
    "    Evaluate predicted structured HTML against ground truth matched_html using ROUGE-1.\n",
    "    \"\"\"\n",
    "    import pandas as pd, os\n",
    "    import evaluate\n",
    "\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in df.index:\n",
    "        # gt_html = df.loc[i, \"matched_html\"]\n",
    "        gt_html = df.loc[i, \"text\"]\n",
    "        pred_path = os.path.join(pred_dir, f\"{model_name}_pred_{i}.html\")\n",
    "        \n",
    "        if not os.path.exists(pred_path):\n",
    "            results.append({\"index\": i, \"ROUGE-1\": None})\n",
    "            continue\n",
    "\n",
    "        with open(pred_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            pred_html = f.read()\n",
    "\n",
    "        score = rouge.compute(\n",
    "            predictions=[pred_html],\n",
    "            references=[gt_html],\n",
    "            use_stemmer=True\n",
    "        )[\"rouge1\"]\n",
    "\n",
    "        results.append({\"index\": i, \"ROUGE-1\": score})\n",
    "\n",
    "    df_out = pd.DataFrame(results)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb194dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ROUGE-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.959906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.815152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.930796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   ROUGE-1\n",
       "0      0  0.959906\n",
       "1      1  0.559486\n",
       "2      2  0.586667\n",
       "3      3  0.815152\n",
       "4      4  0.930796"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = run_html_eval(data, pred_dir, model_name, lang, eval_output)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b41fe",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddbe103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.7704\n",
      "End of Demo!\n"
     ]
    }
   ],
   "source": [
    "if len(df_eval):\n",
    "    macro_rouge1 = df_eval[\"ROUGE-1\"].dropna().mean() if not df_eval[\"ROUGE-1\"].dropna().empty else float('nan')\n",
    "    print(f\"Average ROUGE-1: {macro_rouge1:.4f}\" if not math.isnan(macro_rouge1) else \"No valid ROUGE scores.\")\n",
    "else:\n",
    "    print(\"No evaluation results.\")\n",
    "\n",
    "print(\"End of Demo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
